{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7386b1",
   "metadata": {},
   "source": [
    "# Portuguese Experiment\n",
    "\n",
    "Similarly to the English Experiment, here we try to retrieve pesticide names based on substrings. The difference here is that we translate the substrings from the other experiments to use as seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d24f85",
   "metadata": {},
   "source": [
    "**Libraries**\n",
    "\n",
    "The *os* module is a built-in library that provides functions for interacting with the *operating system*.\n",
    "\n",
    "The *re* module provides *regular expression* matching operations.\n",
    "\n",
    "*Pandas* is a library used for data manipulation and analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d39326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e471c",
   "metadata": {},
   "source": [
    "**Token count**\n",
    "\n",
    "Pre-processing and total count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc17b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682688"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Token Count\n",
    "\n",
    "def token_count(folder_path):\n",
    "    token_list = []\n",
    "    # Loop through all .txt files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                text = file.read().lower()\n",
    "                text = re.sub(r'[^\\w\\s-]', '', text)  # keep hyphens, remove other punctuation\n",
    "                tokens = re.findall(r'\\b\\w+(?:-\\w+)*\\b', text)\n",
    "                token_list.extend(tokens)\n",
    "\n",
    "    total_tokens = len(token_list)\n",
    "    return total_tokens\n",
    "\n",
    "Folder = \"Docs_Portuguese\"\n",
    "token_count(Folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60a8131",
   "metadata": {},
   "source": [
    "**Predicting keywords based on 'morphemes'**\n",
    "\n",
    "The goal of this experiment is to extract pesticide names by using substrings (that may or may not be morphemes) from a list of strings. Based on the top 10 substrings ranging in size from *2 to 5* characters. This experiment is run 4 times, with a decreasing number of substrings used in each run (2-5, 3-5, 4-5, and 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4820c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matching_strings_from_txt(path, substrings):\n",
    "    matches = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "        words = re.findall(r\"\\b\\w+(?:-\\w+)*\\b\", text)  # extract all words\n",
    "        for word in words:\n",
    "            if any(sub in word for sub in substrings):\n",
    "                matches.add(word)\n",
    "    return matches\n",
    "\n",
    "def scrape_txt_folder(folder_path, substrings):\n",
    "    results = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            matched_words = extract_matching_strings_from_txt(full_path, substrings)\n",
    "            if matched_words:\n",
    "                results[filename] = matched_words\n",
    "    return results\n",
    "\n",
    "def merge_unique(found_matches):\n",
    "    merged = set()\n",
    "    for words in found_matches.values():\n",
    "        merged.update(words)\n",
    "    return sorted(merged)\n",
    "\n",
    "def save_list_to_excel(string_list, filename=\"unique_matches_pt_1.xlsx\"):\n",
    "    df = pd.DataFrame(string_list, columns=[\"Matched Strings\"])\n",
    "    df.to_excel(filename, index=False)\n",
    "    print(f\"Excel file saved as: {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6110a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [\n",
    "    \"acefato\", \"azametifós\", \"azinfos\", \"azinfós\", \"azinfos metil\", \"azinfós metil\",\n",
    "    \"azinfós-etílico\", \"azinfos-metil\", \"azinfós-metilico\", \"azinfós-metílico\", \"azinfosmetil\",\n",
    "    \"bromofós\", \"bromofós etílico\", \"bromofós-etílico\", \"bromofós-metílico\", \"bromofósetílico\",\n",
    "    \"cadusafós\", \"carbofenotion\", \"carbofenotiona\", \"carbofention\", \"chlorpyrifos\",\n",
    "    \"clorfenrifós\", \"clorfenvinfos\", \"clorfenvinfós\", \"clorpirifos\", \"clorpirifós\",\n",
    "    \"clorpirifós etil\", \"clorpirifós etílico\", \"clorpirifós metílico\", \"clorpirifós-metil\",\n",
    "    \"clorpirifós-metílico\", \"clorpirifos-oxon\", \"clorpirifós-oxon\", \"clorpiripos\",\n",
    "    \"clorpirofós\", \"clorthion\", \"clortiofos\", \"clortion\", \"crufomato\", \"cumafós\", \"DDVP\", \"DEF\",\n",
    "    \"demetom-S-metílico\", \"demeton\", \"demeton-S\", \"demeton-S-metílico\", \"diazinom\", \"diazinon\",\n",
    "    \"diazinona\", \"diazoxon\", \"dichlorvos\", \"diclorvos\", \"diclorvós\", \"diclórvos\", \"dicrotofos\",\n",
    "    \"dimetoato\", \"dimixion\", \"dioxation\", \"dissulfotom\", \"dissulfoton\", \"dissulfotona\",\n",
    "    \"disulfoton\", \"edifenfós\", \"etefom\", \"etefon\", \"ethion\", \"etil paration\", \"etil-paration\",\n",
    "    \"etion\", \"etiona\", \"etoprofos\", \"etoprofós\", \"etrinfos\", \"etrinfós\", \"etropofós\", \"fenamifos\",\n",
    "    \"fenamifós\", \"fenclorfós\", \"fenitrothion\", \"fenitrotion\", \"fenitrotiona\", \"fensulfotion\",\n",
    "    \"fenthion\", \"fention\", \"fentiona\", \"fentoato\", \"forato\", \"formotion\", \"formotiona\", \"fosalona\",\n",
    "    \"fosetil\", \"fosetyl al\", \"fosfamidom\", \"fosfamidon\", \"fosfamidona\", \"fosmete\", \"fostiazato\",\n",
    "    \"foxim\", \"glifosate\", \"glifosato\", \"glufosinato\", \"glyphosate\", \"heptenofos\", \"hostathion\",\n",
    "    \"iodofenfós\", \"iprobenfos\", \"isazofós\", \"isocarbophos\", \"isomalathion\", \"isomalation\",\n",
    "    \"isoxation\", \"leptofós\", \"malaoxon\", \"malaoxona\", \"malathion\", \"malatião\", \"malation\",\n",
    "    \"malationa\", \"metamidofos\", \"metamidofós\", \"metaminofós\", \"methamidofós\", \"methamidophos\",\n",
    "    \"methyl parathion\", \"metidation\", \"metidationa\", \"metil paraoxon\", \"metil paration\",\n",
    "    \"metil paroxon\", \"metil-paraoxon\", \"metil-paration\", \"metilparaoxon\", \"metilparation\",\n",
    "    \"mevinfos\", \"mevinfós\", \"mipafox\", \"monocrotofos\", \"monocrotofós\", \"naled\", \"nalede\",\n",
    "    \"paraoxon\", \"paraoxon etílico\", \"paraoxon-etílico\", \"paraoxon-metílico\", \"paraoxona\",\n",
    "    \"paraoxona etílica\", \"parathion\", \"parathion methyl\", \"paratião\", \"paratião-metil\",\n",
    "    \"paratiom metílico\", \"paration\", \"paration etílico\", \"paration metílico\", \"parationa\",\n",
    "    \"parationa metílica\", \"parationa-etílica\", \"parationa-metílica\", \"parationametílica\",\n",
    "    \"paraxon\", \"paroxon\", \"pirazofós\", \"piridafentiona\", \"pirimifos metílico\", \"pirimifós metílico\",\n",
    "    \"pirimifós-etílico\", \"pirimifós-metil\", \"pirimifós-metílico\", \"profenofós\", \"prothiofos\",\n",
    "    \"protiofós\", \"quinafós\", \"quinalfos\", \"quinalfós\", \"quinófos\", \"quinolphos\", \"sulfotepp\",\n",
    "    \"sulprofós\", \"tebupirifós\", \"tebupirinfós\", \"TEEP\", \"temefós\", \"temephos\", \"TEPP\", \"terbufos\",\n",
    "    \"terbufós\", \"tetraclorvinfós\", \"tiometon\", \"tiometona\", \"tolclofos metil\", \"tolclofosmetil\",\n",
    "    \"triazofos\", \"triazofós\", \"tribufós\", \"trichlorfon\", \"triclorfom\", \"triclorfon\", \"vamidationa\",\n",
    "    \"vamidotion\", \"vamidotiona\"] #Ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f832f",
   "metadata": {},
   "source": [
    "**Experiment 1**\n",
    "\n",
    "Strings 2-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ea7fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as: unique_matches_pt_1.xlsx\n"
     ]
    }
   ],
   "source": [
    "substrings_to_search1 = ['os', 'on', 'ho', 'f', 't', 'fo', 'hi', 'et', 'io', 'ox', \n",
    "                        'fo', 'os', 'ti', 'fos', 'io', 'ion', 'cl', 'lo', 'lor', 'met',\n",
    "                        'fos', 'tio', 'ion', 'clo', 'lor', 'para', 'oxon', 'ati', 'ofo', 'lorp',\n",
    "                        'tion', 'clor', 'atio', 'ofos', 'lorp', 'nfos', 'lorpi', 'orpir', 'demet', 'meton']\n",
    "\n",
    "folder_path = \"Docs_Portuguese\"\n",
    "\n",
    "found_matches1 = scrape_txt_folder(folder_path, substrings_to_search1)\n",
    "\n",
    "all_unique_words1 = merge_unique(found_matches1)\n",
    "\n",
    "save_list_to_excel(all_unique_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d48dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Experiment 1 - 2-5 ##\n",
      "\n",
      "Predicted words:  24393\n",
      "Ground truth:  200\n",
      "Matches: 155\n",
      "False positives:  24238\n",
      "False negatives:  45\n"
     ]
    }
   ],
   "source": [
    "def read_column_as_list(filename, column_name):\n",
    "    df = pd.read_excel(filename)\n",
    "    return df[column_name].dropna().astype(str).tolist()\n",
    "\n",
    "def get_common_strings(list1, list2):\n",
    "    return sorted(set(list1) & set(list2))\n",
    "\n",
    "list1 = read_column_as_list(\"unique_matches_pt_1.xlsx\", \"Matched Strings\")\n",
    "\n",
    "true_positives1 = get_common_strings(list1, ground_truth)\n",
    "\n",
    "count_ground_truth = len(ground_truth)\n",
    "\n",
    "count_predictions1 = len(list1)\n",
    "\n",
    "false_positives1 = count_predictions1 - len(true_positives1)\n",
    "\n",
    "false_negatives1 = count_ground_truth - len(true_positives1)\n",
    "\n",
    "print('## Experiment 1 - 2-5 ##\\n')\n",
    "print('Predicted words: ', count_predictions1)\n",
    "print('Ground truth: ', count_ground_truth)\n",
    "print('Matches:', len(true_positives1))\n",
    "print('False positives: ', false_positives1) \n",
    "print('False negatives: ', false_negatives1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8e3de",
   "metadata": {},
   "source": [
    "**Evaluation 1**\n",
    "\n",
    "Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4319cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.006354281966137827\n",
      "Recall:  0.775\n",
      "F1:  0.012605212865449517\n"
     ]
    }
   ],
   "source": [
    "def precision_recall(true_positives, false_positives, false_negatives):\n",
    "    tp = len(true_positives)\n",
    "    fp = false_positives\n",
    "    fn = false_negatives\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    print('Precision: ', precision), print('Recall: ', recall), print('F1: ', f1)\n",
    "\n",
    "precision_recall(true_positives1,false_positives1, false_negatives1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8987d",
   "metadata": {},
   "source": [
    "**Experiment 2**\n",
    "\n",
    "Strings 3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a6cef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as: unique_matches_pt_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "substrings_to_search2 = ['fo', 'os', 'ti', 'fos', 'io', 'ion', 'cl', 'lo', 'lor', 'met',\n",
    "                        'fos', 'tio', 'ion', 'clo', 'lor', 'para', 'oxon', 'ati', 'ofo', 'lorp',\n",
    "                        'tion', 'clor', 'atio', 'ofos', 'lorp', 'nfos', 'lorpi', 'orpir', 'demet', 'meton']\n",
    "\n",
    "folder_path = \"Docs_Portuguese\"\n",
    "\n",
    "found_matches2 = scrape_txt_folder(folder_path, substrings_to_search2)\n",
    "\n",
    "all_unique_words2 = merge_unique(found_matches2)\n",
    "\n",
    "save_list_to_excel(all_unique_words2, filename='unique_matches_pt_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361eb0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Experiment 2 - 3-5 ##\n",
      "\n",
      "Predicted words:  11665\n",
      "Ground truth:  200\n",
      "Matches: 126\n",
      "False positives:  11539\n",
      "False negatives:  74\n"
     ]
    }
   ],
   "source": [
    "list2 = read_column_as_list(\"unique_matches_pt_2.xlsx\", \"Matched Strings\")\n",
    "\n",
    "true_positives2 = get_common_strings(list2, ground_truth)\n",
    "\n",
    "count_predictions2 = len(list2)\n",
    "\n",
    "false_positives2 = count_predictions2 - len(true_positives2)\n",
    "\n",
    "false_negatives2 = count_ground_truth - len(true_positives2)\n",
    "\n",
    "print('## Experiment 2 - 3-5 ##\\n')\n",
    "print('Predicted words: ', count_predictions2)\n",
    "print('Ground truth: ', count_ground_truth)\n",
    "print('Matches:', len(true_positives2))\n",
    "print('False positives: ', false_positives2) \n",
    "print('False negatives: ', false_negatives2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3b31a2",
   "metadata": {},
   "source": [
    "**Evaluation 2**\n",
    "\n",
    "Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b63a597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.010801543077582512\n",
      "Recall:  0.63\n",
      "F1:  0.021238938053097345\n"
     ]
    }
   ],
   "source": [
    "precision_recall(true_positives2,false_positives2, false_negatives2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6ecac",
   "metadata": {},
   "source": [
    "**Experiment 3**\n",
    "\n",
    "Strings 4-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427b4966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as: unique_matches_pt_3.xlsx\n"
     ]
    }
   ],
   "source": [
    "substrings_to_search3 = ['fos', 'tio', 'ion', 'clo', 'lor', 'para', 'oxon', 'ati', 'ofo', 'lorp',\n",
    "                        'tion', 'clor', 'atio', 'ofos', 'lorp', 'nfos', 'lorpi', 'orpir', 'demet', 'meton']\n",
    "\n",
    "folder_path = \"Docs_Portuguese\"\n",
    "\n",
    "found_matches3 = scrape_txt_folder(folder_path, substrings_to_search3)\n",
    "\n",
    "all_unique_words3 = merge_unique(found_matches3)\n",
    "\n",
    "save_list_to_excel(all_unique_words3, filename='unique_matches_pt_3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3ba8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Experiment 3 - 4-5 ##\n",
      "\n",
      "Predicted words:  2709\n",
      "Ground truth:  200\n",
      "Matches: 102\n",
      "False positives:  2607\n",
      "False negatives:  98\n"
     ]
    }
   ],
   "source": [
    "list3 = read_column_as_list(\"unique_matches_pt_3.xlsx\", \"Matched Strings\")\n",
    "\n",
    "true_positives3 = get_common_strings(list3, ground_truth)\n",
    "\n",
    "count_predictions3 = len(list3)\n",
    "\n",
    "false_positives3 = count_predictions3 - len(true_positives3)\n",
    "\n",
    "false_negatives3 = count_ground_truth - len(true_positives3)\n",
    "\n",
    "print('## Experiment 3 - 4-5 ##\\n')\n",
    "print('Predicted words: ', count_predictions3)\n",
    "print('Ground truth: ', count_ground_truth)\n",
    "print('Matches:', len(true_positives3))\n",
    "print('False positives: ', false_positives3) \n",
    "print('False negatives: ', false_negatives3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ecfabe",
   "metadata": {},
   "source": [
    "**Evaluation 3**\n",
    "\n",
    "Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db26406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.03765227021040975\n",
      "Recall:  0.51\n",
      "F1:  0.07012719147473359\n"
     ]
    }
   ],
   "source": [
    "precision_recall(true_positives3,false_positives3, false_negatives3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b767ce8",
   "metadata": {},
   "source": [
    "**Experiment 4**\n",
    "\n",
    "Strings 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "066bf55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as: unique_matches_pt_4.xlsx\n"
     ]
    }
   ],
   "source": [
    "substrings_to_search4 = ['tion', 'clor', 'atio', 'ofos', 'lorp', 'nfos', 'lorpi', 'orpir', 'demet', 'meton']\n",
    "\n",
    "folder_path = \"Docs_Portuguese\"\n",
    "\n",
    "found_matches4 = scrape_txt_folder(folder_path, substrings_to_search4)\n",
    "\n",
    "all_unique_words4 = merge_unique(found_matches4)\n",
    "\n",
    "save_list_to_excel(all_unique_words4, filename='unique_matches_pt_4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd284de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Experiment 4 - 5 ##\n",
      "\n",
      "Predicted words:  926\n",
      "Ground truth:  200\n",
      "Matches: 67\n",
      "False positives:  859\n",
      "False negatives:  133\n"
     ]
    }
   ],
   "source": [
    "list4 = read_column_as_list(\"unique_matches_pt_4.xlsx\", \"Matched Strings\")\n",
    "\n",
    "true_positives4 = get_common_strings(list4, ground_truth)\n",
    "\n",
    "count_predictions4 = len(list4)\n",
    "\n",
    "false_positives4 = count_predictions4 - len(true_positives4)\n",
    "\n",
    "false_negatives4 = count_ground_truth - len(true_positives4)\n",
    "\n",
    "print('## Experiment 4 - 5 ##\\n')\n",
    "print('Predicted words: ', count_predictions4)\n",
    "print('Ground truth: ', count_ground_truth)\n",
    "print('Matches:', len(true_positives4))\n",
    "print('False positives: ', false_positives4) \n",
    "print('False negatives: ', false_negatives4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a671010",
   "metadata": {},
   "source": [
    "**Evaluation 4**\n",
    "\n",
    "Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50254c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.07235421166306695\n",
      "Recall:  0.335\n",
      "F1:  0.11900532859680285\n"
     ]
    }
   ],
   "source": [
    "precision_recall(true_positives4,false_positives4, false_negatives4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
